{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f03c6d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Raw text loaded.\n",
      "Text Preview:\n",
      " The Great\n",
      "Gatsby\n",
      "By F. Scott Fitzgerald\n",
      "Download free eBooks of classic literature, books\n",
      "and novels at Planet eBook. Subscribe to our free\n",
      "eBooks blog and email newsletter.\n",
      "Then wear the gold hat, if that will move her;\n",
      "If you can bounce high, bounce for her too,\n",
      "Till she cry â€˜Lover, gold-hatted,\n",
      "high-bouncing lover, I must have you!â€™\n",
      "\n",
      "â€”THOMAS PARKE Dâ€™INVILLIERS\n",
      "The Great Gatsby\n",
      "Chapter 1\n",
      "\n",
      "In my younger and more vulnerable years my father gave\n",
      "me some advice that Iâ€™ve been turning over in my\n",
      "mi\n",
      "Contains key quote? False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ“Œ STEP 1: Load PDF\n",
    "# ========================================\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "pdf_path = \"./PDF's/The_Great_Gatsby.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "pages = [page.get_text() for page in doc]\n",
    "\n",
    "\n",
    "print(\"ğŸ” Raw text loaded.\")\n",
    "print(\"Text Preview:\\n\", raw_text[:500])\n",
    "\n",
    "print(\"Contains key quote?\", \"hope sheâ€™ll be a fool\" in raw_text)\n",
    "print(\"fool\" in raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d56644cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Created Chunk 0 (Page: 1)\n",
      "ğŸ“Œ Created Chunk 1 (Page: 2)\n",
      "ğŸ“Œ Created Chunk 2 (Page: 3)\n",
      "ğŸ“Œ Created Chunk 3 (Page: 4)\n",
      "ğŸ“Œ Created Chunk 4 (Page: 5)\n",
      "ğŸ“Œ Created Chunk 5 (Page: 6)\n",
      "ğŸ“Œ Created Chunk 6 (Page: 7)\n",
      "ğŸ“Œ Created Chunk 7 (Page: 8)\n",
      "ğŸ“Œ Created Chunk 8 (Page: 9)\n",
      "ğŸ“Œ Created Chunk 9 (Page: 10)\n",
      "ğŸ“Œ Created Chunk 10 (Page: 11)\n",
      "ğŸ“Œ Created Chunk 11 (Page: 12)\n",
      "ğŸ“Œ Created Chunk 12 (Page: 13)\n",
      "ğŸ“Œ Created Chunk 13 (Page: 14)\n",
      "ğŸ“Œ Created Chunk 14 (Page: 15)\n",
      "ğŸ“Œ Created Chunk 15 (Page: 16)\n",
      "ğŸ“Œ Created Chunk 16 (Page: 17)\n",
      "ğŸ“Œ Created Chunk 17 (Page: 18)\n",
      "ğŸ“Œ Created Chunk 18 (Page: 19)\n",
      "ğŸ“Œ Created Chunk 19 (Page: 20)\n",
      "ğŸ“Œ Created Chunk 20 (Page: 21)\n",
      "ğŸ“Œ Created Chunk 21 (Page: 22)\n",
      "ğŸ“Œ Created Chunk 22 (Page: 23)\n",
      "ğŸ“Œ Created Chunk 23 (Page: 24)\n",
      "ğŸ“Œ Created Chunk 24 (Page: 25)\n",
      "ğŸ“Œ Created Chunk 25 (Page: 26)\n",
      "ğŸ“Œ Created Chunk 26 (Page: 27)\n",
      "ğŸ“Œ Created Chunk 27 (Page: 28)\n",
      "ğŸ“Œ Created Chunk 28 (Page: 29)\n",
      "ğŸ“Œ Created Chunk 29 (Page: 30)\n",
      "ğŸ“Œ Created Chunk 30 (Page: 31)\n",
      "ğŸ“Œ Created Chunk 31 (Page: 32)\n",
      "ğŸ“Œ Created Chunk 32 (Page: 33)\n",
      "ğŸ“Œ Created Chunk 33 (Page: 34)\n",
      "ğŸ“Œ Created Chunk 34 (Page: 35)\n",
      "ğŸ“Œ Created Chunk 35 (Page: 36)\n",
      "ğŸ“Œ Created Chunk 36 (Page: 37)\n",
      "ğŸ“Œ Created Chunk 37 (Page: 38)\n",
      "ğŸ“Œ Created Chunk 38 (Page: 39)\n",
      "ğŸ“Œ Created Chunk 39 (Page: 40)\n",
      "ğŸ“Œ Created Chunk 40 (Page: 41)\n",
      "ğŸ“Œ Created Chunk 41 (Page: 42)\n",
      "ğŸ“Œ Created Chunk 42 (Page: 43)\n",
      "ğŸ“Œ Created Chunk 43 (Page: 44)\n",
      "ğŸ“Œ Created Chunk 44 (Page: 45)\n",
      "ğŸ“Œ Created Chunk 45 (Page: 46)\n",
      "ğŸ“Œ Created Chunk 46 (Page: 47)\n",
      "ğŸ“Œ Created Chunk 47 (Page: 48)\n",
      "ğŸ“Œ Created Chunk 48 (Page: 49)\n",
      "ğŸ“Œ Created Chunk 49 (Page: 50)\n",
      "ğŸ“Œ Created Chunk 50 (Page: 51)\n",
      "ğŸ“Œ Created Chunk 51 (Page: 52)\n",
      "ğŸ“Œ Created Chunk 52 (Page: 53)\n",
      "ğŸ“Œ Created Chunk 53 (Page: 54)\n",
      "ğŸ“Œ Created Chunk 54 (Page: 55)\n",
      "ğŸ“Œ Created Chunk 55 (Page: 56)\n",
      "ğŸ“Œ Created Chunk 56 (Page: 57)\n",
      "ğŸ“Œ Created Chunk 57 (Page: 58)\n",
      "ğŸ“Œ Created Chunk 58 (Page: 59)\n",
      "ğŸ“Œ Created Chunk 59 (Page: 60)\n",
      "ğŸ“Œ Created Chunk 60 (Page: 61)\n",
      "ğŸ“Œ Created Chunk 61 (Page: 62)\n",
      "ğŸ“Œ Created Chunk 62 (Page: 63)\n",
      "ğŸ“Œ Created Chunk 63 (Page: 64)\n",
      "ğŸ“Œ Created Chunk 64 (Page: 65)\n",
      "ğŸ“Œ Created Chunk 65 (Page: 66)\n",
      "ğŸ“Œ Created Chunk 66 (Page: 67)\n",
      "ğŸ“Œ Created Chunk 67 (Page: 68)\n",
      "ğŸ“Œ Created Chunk 68 (Page: 69)\n",
      "ğŸ“Œ Created Chunk 69 (Page: 70)\n",
      "ğŸ“Œ Created Chunk 70 (Page: 71)\n",
      "ğŸ“Œ Created Chunk 71 (Page: 72)\n",
      "ğŸ“Œ Created Chunk 72 (Page: 73)\n",
      "ğŸ“Œ Created Chunk 73 (Page: 74)\n",
      "ğŸ“Œ Created Chunk 74 (Page: 75)\n",
      "ğŸ“Œ Created Chunk 75 (Page: 76)\n",
      "ğŸ“Œ Created Chunk 76 (Page: 77)\n",
      "ğŸ“Œ Created Chunk 77 (Page: 78)\n",
      "ğŸ“Œ Created Chunk 78 (Page: 79)\n",
      "ğŸ“Œ Created Chunk 79 (Page: 80)\n",
      "ğŸ“Œ Created Chunk 80 (Page: 81)\n",
      "ğŸ“Œ Created Chunk 81 (Page: 82)\n",
      "ğŸ“Œ Created Chunk 82 (Page: 83)\n",
      "ğŸ“Œ Created Chunk 83 (Page: 84)\n",
      "ğŸ“Œ Created Chunk 84 (Page: 85)\n",
      "ğŸ“Œ Created Chunk 85 (Page: 86)\n",
      "ğŸ“Œ Created Chunk 86 (Page: 87)\n",
      "ğŸ“Œ Created Chunk 87 (Page: 88)\n",
      "ğŸ“Œ Created Chunk 88 (Page: 89)\n",
      "ğŸ“Œ Created Chunk 89 (Page: 90)\n",
      "ğŸ“Œ Created Chunk 90 (Page: 91)\n",
      "\n",
      "âœ… Total Chunks: 91\n",
      "ğŸ§© Sample Chunk:\n",
      " always had the impression\n",
      "that he approved of me\n",
      "and wanted me to like him with some harsh, defiant\n",
      "wistfulness of his own.\n",
      "We talked for a few minutes on the sunny porch.\n",
      "â€˜Iâ€™ve got a nice place here,â€™ he said, his eyes flashing\n",
      "about restlessly.\n",
      "Turning me around by one arm he moved a broad\n",
      "flat hand along the front vista, including in its sweep a\n",
      "sunken Italian garden, a half acre of deep pungen\n",
      "ğŸ“ Metadata: {'chunk_id': 10, 'source': 'Chunk 11', 'char_range': '8000-8800', 'word_count': 264, 'page_number': 11}\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ“Œ STEP 2: Chunking with Page Numbers\n",
    "# ========================================\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "chunk_id = 0\n",
    "\n",
    "for page_num, page_text in enumerate(pages, start=1):  # start=1 for 1-based page numbers\n",
    "    page_chunks = splitter.create_documents([page_text])\n",
    "    for doc in page_chunks:\n",
    "        content = doc.page_content\n",
    "        doc.metadata = {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"source\": f\"Chunk {chunk_id+1}\",\n",
    "            \"char_range\": f\"{chunk_id*800}-{(chunk_id+1)*800}\",\n",
    "            \"word_count\": len(content.split()),\n",
    "            \"page_number\": page_num\n",
    "        }\n",
    "        print(f\"ğŸ“Œ Created Chunk {chunk_id} (Page: {page_num})\")\n",
    "        chunks.append(doc)\n",
    "        chunk_id += 1\n",
    "\n",
    "print(f\"\\nâœ… Total Chunks: {len(chunks)}\")\n",
    "print(\"ğŸ§© Sample Chunk:\\n\", chunks[10].page_content[:400])\n",
    "print(\"ğŸ“ Metadata:\", chunks[10].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e620514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d6ff496efd4fab819ad44dc25229a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings generated.\n",
      "Embedding shape: (91, 768)\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ“Œ STEP 3: Embed Chunks\n",
    "# ========================================\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "embeddings = embedding_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "print(\"âœ… Embeddings generated.\")\n",
    "print(\"Embedding shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "002190fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index built. Total vectors: 91\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ“Œ STEP 4: Store in FAISS\n",
    "# ========================================\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(np.array(embeddings))\n",
    "\n",
    "print(\"âœ… FAISS index built. Total vectors:\", faiss_index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e3b1927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª Top Chunks for Query:\n",
      "\n",
      "Chunk 1 (Score-based):\n",
      " â€˜Thatâ€™s true.â€™ She hesitated. â€˜Well, Iâ€™ve had a very\n",
      "bad time, Nick, and Iâ€™m pretty cynical about\n",
      "everything.â€™ Evidently she had reason to be. I waited\n",
      "but she didnâ€™t say any more, and after a moment I\n",
      "returned rather feebly to the subject of her daughter.\n",
      "â€˜I suppose she talks, andâ€”eats, and everyth \n",
      "Metadata: {'chunk_id': 21, 'source': 'Chunk 22', 'char_range': '16800-17600', 'word_count': 263, 'page_number': 22}\n",
      "\n",
      "Chunk 2 (Score-based):\n",
      " Hot Springs and Palm Beach. I had heard some story\n",
      "of her too, a critical, unpleasant story, but what it was\n",
      "I had forgot ten long ago.\n",
      "â€˜Good night,â€™ she said softly. â€˜Wake me at eight,\n",
      "wonâ€™t you.â€™\n",
      "â€˜If youâ€™ll get up.â€™\n",
      "â€˜I will. Good night, Mr. Carraway. See you anon.â€™ â€˜Of\n",
      "course you will,â€™ confirmed  \n",
      "Metadata: {'chunk_id': 23, 'source': 'Chunk 24', 'char_range': '18400-19200', 'word_count': 234, 'page_number': 24}\n",
      "\n",
      "Chunk 3 (Score-based):\n",
      " said.\n",
      "â€˜Donâ€™t talk. I want to hear what happens.â€™\n",
      "â€˜Is something happening?â€™ I inquired innocently.\n",
      "â€˜You mean to say you donâ€™t know?â€™ said Miss Baker,\n",
      "hon estly surprised. â€˜I thought everybody knew.â€™\n",
      "â€˜I donâ€™t.â€™\n",
      "â€˜Whyâ€”â€”â€™ she said hesitantly, â€˜Tomâ€™s got some\n",
      "woman in New York.â€™\n",
      "â€˜Got some woman?â€™ I repeat \n",
      "Metadata: {'chunk_id': 19, 'source': 'Chunk 20', 'char_range': '15200-16000', 'word_count': 220, 'page_number': 20}\n",
      "\n",
      "Chunk 4 (Score-based):\n",
      " four candles flickered\n",
      "on the table in the diminished\n",
      "wind.\n",
      "â€˜Why CANDLES?â€™ objected Daisy, frowning. She\n",
      "snapped them out with her fingers. â€˜In two weeks itâ€™ll\n",
      "be the\n",
      "longest day in the year.â€™ She looked at us all\n",
      "radiantly. â€˜Do you always watch for the longest day of\n",
      "the year and then\n",
      "miss it? I al \n",
      "Metadata: {'chunk_id': 15, 'source': 'Chunk 16', 'char_range': '12000-12800', 'word_count': 242, 'page_number': 16}\n",
      "\n",
      "Chunk 5 (Score-based):\n",
      " â€˜Sheâ€™s asleep. Sheâ€™s two years old. Havenâ€™t you\n",
      "ever seen her?â€™\n",
      "â€˜Never.â€™\n",
      "â€˜Well, you ought to see her. Sheâ€™sâ€”â€”â€˜\n",
      "Tom Buchanan who had been hovering restlessly\n",
      "about the room stopped and rested his hand on my\n",
      "shoulder.\n",
      "12 The Great Gatsby\n",
      "â€˜What you doing, Nick?â€™\n",
      "â€˜Iâ€™m a bond man.â€™\n",
      "â€˜Who with?â€™\n",
      "I told him \n",
      "Metadata: {'chunk_id': 13, 'source': 'Chunk 14', 'char_range': '10400-11200', 'word_count': 201, 'page_number': 14}\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ“Œ STEP 5: Retrieval + Reranking\n",
    "# ========================================\n",
    "from transformers import GPT2TokenizerFast\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def retrieve_top_k_chunks(query, k=20, max_tokens=3500):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    distances, indices = faiss_index.search(np.array(query_embedding), k)\n",
    "\n",
    "    candidate_chunks = []\n",
    "    for i in indices[0]:\n",
    "        candidate_chunks.append(chunks[i])\n",
    "\n",
    "    # ğŸ” Rerank using cross-encoder\n",
    "    pairs = [(query, chunk.page_content) for chunk in candidate_chunks]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    ranked_chunks = sorted(zip(scores, candidate_chunks), reverse=True)\n",
    "\n",
    "    selected = []\n",
    "    total_tokens = 0\n",
    "    for score, chunk in ranked_chunks:\n",
    "        tokens = len(tokenizer.encode(chunk.page_content))\n",
    "        if total_tokens + tokens <= max_tokens:\n",
    "            selected.append(chunk)\n",
    "            total_tokens += tokens\n",
    "        if len(selected) >= 5:  # top 5 relevant\n",
    "            break\n",
    "\n",
    "    return selected\n",
    "\n",
    "# âœ… Retrieval Tester\n",
    "test_query = \"What did Daisy say when her daughter was born?\"\n",
    "test_results = retrieve_top_k_chunks(test_query)\n",
    "print(\"\\nğŸ§ª Top Chunks for Query:\")\n",
    "for i, doc in enumerate(test_results):\n",
    "    print(f\"\\nChunk {i+1} (Score-based):\\n\", doc.page_content[:300], \"\\nMetadata:\", doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77308db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§± Total tokens in truncated context: 820\n",
      "\n",
      "ğŸ“„ Top-k Retrieved Context:\n",
      "\n",
      "[Page 14] â€˜Sheâ€™s asleep. Sheâ€™s two years old. Havenâ€™t you\n",
      "ever seen her?â€™\n",
      "â€˜Never.â€™\n",
      "â€˜Well, you ought to see her. Sheâ€™sâ€”â€”â€˜\n",
      "Tom Buchanan who had been hovering restlessly\n",
      "about the room stopped and rested his hand on my\n",
      "shoulder.\n",
      "12 The Great Gatsby\n",
      "â€˜What you doing, Nick?â€™\n",
      "â€˜Iâ€™m a bond man.â€™\n",
      "â€˜Who with?â€™\n",
      "I told him.\n",
      "â€˜Never heard of them,â€™ he remarked\n",
      "decisively. This annoyed me.\n",
      "â€˜You will,â€™ I answered shortly. â€˜You will if you stay in\n",
      "the East.â€™\n",
      "â€˜Oh, Iâ€™ll stay in the East, donâ€™t you worry,â€™ he said,\n",
      "glanc ing at Daisy and then back at me, as if he were\n",
      "alert for something more. â€˜Iâ€™d be a God Damned fool\n",
      "to live any where else.â€™\n",
      "At this point Miss Baker said â€˜Absolutely!â€™ with such\n",
      "suddenness that I startedâ€”it was the first word she\n",
      "uttered\n",
      "since I came into the room. Evidently it\n",
      "surprised her as\n",
      "much as it did me, for she yawned\n",
      "and with a series of rapid, deft movements stood up\n",
      "into the room.\n",
      "â€˜Iâ€™m stiff,â€™ she complained, â€˜Iâ€™ve been lying on that\n",
      "sofa for as long as I can remember.â€™\n",
      "â€˜Donâ€™t\n",
      "\n",
      "ğŸ“˜ Final Answer from Gemini:\n",
      "\n",
      "Based on the context provided, there is no information about Gatsby meeting Daisy at Nick's house. The scenes described take place at Tom and Daisy's home.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ“Œ STEP 6: Ask Question with Gemini (No Summarization)\n",
    "# ========================================\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load environment & API key\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Ask a question\n",
    "query = input(\"ğŸ” Enter your question: \").strip()\n",
    "\n",
    "# Get top chunks\n",
    "retrieved = retrieve_top_k_chunks(query)\n",
    "\n",
    "if not retrieved:\n",
    "    print(\"âš ï¸ No relevant context found.\")\n",
    "    exit()\n",
    "\n",
    "joined_chunks = [\n",
    "    f\"[Page {c.metadata['page_number']}] {c.page_content}\"\n",
    "    for c in retrieved\n",
    "]\n",
    "\n",
    "# Truncate token-wise\n",
    "token_limit = 1000\n",
    "final_context = \"\"\n",
    "total_tokens = 0\n",
    "\n",
    "for chunk in joined_chunks:\n",
    "    tokens = tokenizer.encode(chunk)\n",
    "    if total_tokens + len(tokens) > token_limit:\n",
    "        break\n",
    "    final_context += chunk + \"\\n\\n\"\n",
    "    total_tokens += len(tokens)\n",
    "\n",
    "context = final_context.strip()\n",
    "print(f\"\\nğŸ§± Total tokens in truncated context: {total_tokens}\")\n",
    "\n",
    "# ğŸ§  Gemini Prompt\n",
    "system_instruction = (\n",
    "    \"You are a helpful assistant answering questions about a book. \"\n",
    "    \"Use only the provided context and cite the chunk number when possible. \"\n",
    "    \"Be accurate and concise. Don't guess beyond the context.\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    f\"{system_instruction}\\n\\n\"\n",
    "    f\"Context:\\n{context}\\n\\n\"\n",
    "    f\"Question: {query}\"\n",
    ")\n",
    "\n",
    "# Generate Answer\n",
    "model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Show results\n",
    "print(\"\\nğŸ“„ Top-k Retrieved Context:\\n\")\n",
    "print(context[:1000])  # Preview\n",
    "\n",
    "print(\"\\nğŸ“˜ Final Answer from Gemini:\\n\")\n",
    "print(response.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c671aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-2.5-flash-lite\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-preview\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n"
     ]
    }
   ],
   "source": [
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e630900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(any(\"hope sheâ€™ll be a fool\" in c.page_content for c in chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ccaae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settee.\n",
      "Daisy took her face in her hands, as if feeling its\n",
      "love ly shape, and her eyes moved gradually out into\n",
      "the velvet dusk. I saw that turbulent emotions\n",
      "possessed her, so I asked what I thought would be\n",
      "some sedative questions about her little girl.\n",
      "Free eBooks at Planet eBook.com 19\n",
      "â€˜We donâ€™\n",
      "sea in a boat, and all that sort of thingâ€”â€”â€˜\n",
      "â€˜Good night,â€™ called Miss Baker from the stairs. â€˜I\n",
      "havenâ€™t heard a word.â€™\n",
      "â€˜Sheâ€™s a nice girl,â€™ said Tom after a moment. â€˜They\n",
      "oughtnâ€™t to let her run around the country this way.â€™\n",
      "â€˜Who oughtnâ€™t to?â€™ inquired Daisy coldly.\n",
      "â€˜Her family.â€™\n",
      "â€˜Her family is one\n",
      "and get married to each other right away.â€™\n",
      "â€˜Doesnâ€™t she like Wilson either?â€™\n",
      "The answer to this was unexpected. It came from\n",
      "Myrtle who had overheard the question and it was\n",
      "violent and ob scene.\n",
      "â€˜You\n",
      "see?â€™\n",
      "cried\n",
      "Catherine\n",
      "triumphantly.\n",
      "She\n",
      "lowered her\n",
      "voice again. â€˜Itâ€™s really his wife thatâ€™s\n",
      "keepi\n",
      "here this summer. I think the home influence will be\n",
      "very good for her.â€™\n",
      "Daisy and Tom looked at each other for a moment\n",
      "in si lence.\n",
      "â€˜Is she from New York?â€™ I asked quickly.\n",
      "â€˜From Louisville. Our white girlhood was passed\n",
      "togeth er there. Our beautiful whiteâ€”â€”â€˜\n",
      "â€˜Did you give Nick a little heart to \n",
      "Almost before I had grasped her meaning there\n",
      "was the\n",
      "flutter of a dress and the crunch of leather\n",
      "boots and Tom and Daisy were back at the table.\n",
      "â€˜It couldnâ€™t be helped!â€™ cried Daisy with tense gayety.\n",
      "She sat down, glanced searchingly at Miss Baker and\n",
      "then at me and continued: â€˜I looked outdoors \n"
     ]
    }
   ],
   "source": [
    "query = \"What did Daisy say when her daughter was born?\"\n",
    "results = retrieve_top_k_chunks(query)\n",
    "for doc in results:\n",
    "    print(doc.page_content[:300])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
